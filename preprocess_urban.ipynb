{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UrbanSound8K pre-processing\n",
    "\n",
    "It creates three files, `train`, `valid`, and `test` + `.h5`\n",
    "\n",
    "Split: folder 1-8: train, 9:valid, 10:test\n",
    "\n",
    "By Keunwoo Choi. 29 Nov 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import librosa\n",
    "import os, sys\n",
    "import time\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup path\n",
    "\n",
    "**Change these to your setup**\n",
    "\n",
    "* **`PATH_US`**: audio folder path\n",
    "* **`path_csv`**: csv file path\n",
    "* **`PATH_HDF`**: output HDF folder path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_US = '/misc/kcgscratch1/ChoGroup/keunwoo/UrbanSound8K/audio/'\n",
    "path_csv = '/misc/kcgscratch1/ChoGroup/keunwoo/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "PATH_HDF = '/misc/kcgscratch1/ChoGroup/keunwoo/urbansound8k_hdf/'\n",
    "# slice_file_name\tfsID\tstart\tend\tsalience\tfold\tclassID\tclass\n",
    "# 100032-3-0-0.wav\t100032\t0\t0.317551\t1\t5\t3\tdog_bark\n",
    "# 100263-2-0-117.wav\t100263\t58.5\t62.5\t1\t5\t2\tchildren_playing\n",
    "# 100263-2-0-121.wav\t100263\t60.5\t64.5\t1\t5\t2\tchildren_playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold_folders = ['fold%d/' % i for i in range(1, 11)]\n",
    "n_label = 10 # 0 - 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio stuff\n",
    "* **Modify these if you want. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# audio\n",
    "SR = 12000 # [Hz]\n",
    "max_len = 4.0 # [Seconds]. should be < 4.0. I recommend not to change it. \n",
    "n_mels = 96\n",
    "n_fft = 512\n",
    "n_hop = 256\n",
    "len_raw = int(SR * max_len)\n",
    "n_freq = n_fft/2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 188)\n",
      "(257, 188)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/kcgscratch1/ChoGroup/keunwoo/venv_k110/lib/python2.7/site-packages/ipykernel/__main__.py:1: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if __name__ == '__main__':\n",
      "/misc/kcgscratch1/ChoGroup/keunwoo/venv_k110/lib/python2.7/site-packages/ipykernel/__main__.py:4: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "mel_shape = librosa.feature.melspectrogram(np.zeros(SR*max_len), SR, n_fft=n_fft, hop_length=n_hop, n_mels=n_mels).shape\n",
    "print mel_shape\n",
    "n_mel_fr = mel_shape[1]\n",
    "stft_shape = librosa.stft(np.zeros(SR*max_len), n_fft, n_hop).shape\n",
    "print stft_shape\n",
    "n_stft_fr = stft_shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8732, 8)\n",
      "7079 816 837\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path_csv, header=0)\n",
    "print df.shape\n",
    "n_data_all = df.shape[0]\n",
    "n_valid = len(df[df['fold']==9])\n",
    "n_test = len(df[df['fold']==10])\n",
    "n_train = n_data_all - n_valid - n_test\n",
    "print n_train, n_valid, n_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling\n",
    "Remember that shuffling should be WITHIN each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from the previous ones\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('shuffled_idxs.npy'):\n",
    "    [train_shfl_idxs, valid_shfl_idxs, test_shfl_idxs] = np.load('shuffled_idxs.npy')\n",
    "    print 'Generated'\n",
    "else:\n",
    "    np.random.seed(1337)  # for reproducibility\n",
    "    train_shfl_idxs = np.random.permutation(n_train)\n",
    "    valid_shfl_idxs = np.random.permutation(n_valid)\n",
    "    test_shfl_idxs = np.random.permutation(n_test)\n",
    "    np.save('shuffled_idxs.npy', [train_shfl_idxs, valid_shfl_idxs, test_shfl_idxs])\n",
    "    print 'Loaded from the previous ones'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to load audio, compute melgram, and store into HDF\n",
    "\n",
    "If you wanna edit or add...\n",
    "1. Add a new feature in `create_dataset_for()`\n",
    "2. Add a new feature in `row_to()` that call `row_to_something()`\n",
    "3. Implement a new function `row_to_something()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset_for(f_hdf, ds_name, num_data):\n",
    "    if ds_name == 'melgram':\n",
    "        return f_hdf.create_dataset('melgram', (num_data, n_mels, n_mel_fr), dtype='float32')\n",
    "    elif ds_name == 'y':\n",
    "        return f_hdf.create_dataset('y', (num_data, n_label), dtype='bool')\n",
    "    elif ds_name == 'raw':\n",
    "        return f_hdf.create_dataset('raw', (num_data, len_raw), dtype='float32')\n",
    "    elif ds_name == 'stft':\n",
    "        return f_hdf.create_dataset('stft', (num_data, n_freq, n_stft_fr), dtype='float32')\n",
    "    else:\n",
    "        print 'ha? %s?' % ds_name\n",
    "\n",
    "def row_to(ds_name, row_idx, row, dataset):\n",
    "    if ds_name == 'melgram':\n",
    "        row_to_melgram(row_idx, row, dataset)\n",
    "    elif ds_name == 'y':\n",
    "        row_to_y(row_idx, row, dataset)\n",
    "    elif ds_name == 'raw':\n",
    "        row_to_raw(row_idx, row, dataset)\n",
    "    elif ds_name == 'stft':\n",
    "        row_to_stft(row_idx, row, dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row_to_stft(row_idx, row, dataset):\n",
    "    '''\n",
    "    row: row of dataframe of pandas\n",
    "    dataset: a dataset of hdf file '''\n",
    "    fname, fold = row[1], row[6]\n",
    "    folder = fold_folders[fold-1]\n",
    "    src, sr = librosa.load(PATH_US + folder + fname, SR)\n",
    "    stft = np.abs(librosa.stft(src, n_fft, n_hop)) ** 2\n",
    "    dataset[row_idx, :, :min(n_stft_fr, stft.shape[1])] = stft[:, :n_stft_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row_to_melgram(row_idx, row, dataset):\n",
    "    '''\n",
    "    row: row of dataframe of pandas\n",
    "    dataset: a dataset of hdf file '''\n",
    "    fname, fold = row[1], row[6]\n",
    "    folder = fold_folders[fold-1]\n",
    "    src, sr = librosa.load(PATH_US + folder + fname, SR)\n",
    "\n",
    "    melgram = librosa.feature.melspectrogram(src, sr, n_fft=n_fft, \n",
    "                                             hop_length=n_hop, n_mels=n_mels)\n",
    "    dataset[row_idx, :, :min(n_mel_fr, melgram.shape[1])] = melgram[:, :n_mel_fr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row_to_y(row_idx, row, dataset):\n",
    "    y = row[7]\n",
    "    dataset[row_idx, y] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row_to_raw(row_idx, row, dataset):\n",
    "    fname, fold = row[1], row[6]\n",
    "    folder = fold_folders[fold-1]\n",
    "    src, sr = librosa.load(PATH_US + folder + fname, SR)\n",
    "    dataset[row_idx, :min(len_raw, len(src))] = src[:len_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to save in hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_to_hdf(hdf_filepath, df_subset, shfl_idxs, ds_name):\n",
    "    '''\n",
    "    Either create (w) or append (a) to a hdf file\n",
    "    hdf_filepath; string, full file path to store hdf\n",
    "    df_subset: pandas data frame,  of the set to store\n",
    "    shfl_idxs: numpy integer array, shuffled index\n",
    "    ds_name: 'melgram', 'y', 'raw', ...\n",
    "    '''\n",
    "    assert len(df_subset) == len(shfl_idxs), 'data frame length != indices list'\n",
    "    start_time = time.time()\n",
    "    num_data = len(df_subset)\n",
    "    if os.path.exists(hdf_filepath):\n",
    "        mode = 'a'\n",
    "    else:\n",
    "        mode = 'w'\n",
    "    with h5py.File(hdf_filepath, mode) as f_hdf:\n",
    "        dataset = create_dataset_for(f_hdf, ds_name, num_data)\n",
    "        for row_idx, row in enumerate(df_subset.iloc[shfl_idxs].itertuples()):\n",
    "            row_to(ds_name, row_idx, row, dataset)\n",
    "            if row_idx % 20 == 0:\n",
    "                sys.stdout.write('\\r%d/%d-th sample (%s) was written.' % (row_idx+1, num_data, ds_name))\n",
    "    print '\\n--- Done: It took %d seconds for %s, %s ---' % \\\n",
    "          (int(time.time() - start_time), ds_name, hdf_filepath.split('/')[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/7079-th sample (stft) was written."
     ]
    }
   ],
   "source": [
    "for ds_name in ['stft', 'raw', 'melgram', 'y']:\n",
    "    set_to_hdf(PATH_HDF+'train.h5', df[df['fold'] < 9], train_shfl_idxs, ds_name)\n",
    "    set_to_hdf(PATH_HDF+'valid.h5', df[df['fold']==9], valid_shfl_idxs, ds_name)\n",
    "    set_to_hdf(PATH_HDF+'test.h5', df[df['fold']==10], test_shfl_idxs, ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done. Wanna standardise them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fname in ['train.h5', 'valid.h5', 'test.h5']:\n",
    "    for dname in ['melgram', 'stft']:\n",
    "        with h5py.File(PATH_HDF + fname, 'a') as f:\n",
    "            mean = np.mean(f[dname])\n",
    "            std = np.std(f[dname])\n",
    "            f[dname][:] = (f[dname][:] - mean)/(std + np.finfo(np.float32).eps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
